{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkVWwJCiLWs71pnKSA2/fO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amanmaurya7/langchain_collab/blob/main/langchain_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "790MVMgAx-jt",
        "outputId": "9d184b59-e82e-4cc4-a9ce-df8fe8d3fcc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.2.8)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.6)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PPLX_API_KEY\"] = \"pplx-\" # your perplexity api key here\n"
      ],
      "metadata": {
        "id": "2ZKuWeknyBf7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models import ChatPerplexity\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "\n",
        "\n",
        "llm = ChatPerplexity(model = 'sonar-pro', temperature=0.3, max_tokens = 500)"
      ],
      "metadata": {
        "id": "eEMuVmRTySox"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', 'You are an senior AI Architect'),\n",
        "    ('human', 'Explain this {topic} in simple terms with examples')\n",
        "])\n",
        "chain  = prompt | llm | StrOutputParser()\n",
        "chain.invoke({'topic':'AWS Bedrock'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "k9X_KR1XysaV",
        "outputId": "1a290a74-cb03-4753-e8a0-d89a9468c233"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"**Amazon Bedrock is a fully managed AWS service that lets you build and deploy generative AI applications using powerful pre-trained foundation models (FMs) from companies like Anthropic, Meta, and Amazon, without managing any servers or infrastructure.**[1][2][6]\\n\\nIt provides a single API to access, experiment with, customize, and integrate these models into apps like chatbots or content generators, handling scaling, security, and privacy automatically.[1][2][3]\\n\\n### Key Features in Simple Terms\\n- **Access Multiple Models**: Choose from dozens of FMs for tasks like text generation, image creation, or summarization—all via one easy API. No need to pick just one provider.[1][2][6]\\n- **No Server Management**: AWS runs everything serverlessly, so you focus on your app, not hardware like GPUs.[1][2][4]\\n- **Customization**: Fine-tune models with your own data (e.g., company documents) using techniques like fine-tuning or Retrieval-Augmented Generation (RAG) to make responses more accurate for your needs.[1][2][3]\\n- **Agents and Guardrails**: Build AI agents that reason, call APIs, and use your data sources; add guardrails to block harmful or biased outputs.[2][3][5]\\n- **Integration and Pricing**: Works seamlessly with AWS tools like S3 or Lambda; pay only for what you use (on-demand, provisioned throughput, or batch for cost savings up to 50%).[1][2][4]\\n\\n### How It Works (3 Simple Steps)\\n1. **Request Model Access**: In the AWS Bedrock console, select a model (e.g., Anthropic's Claude) and get approved in minutes.[1]\\n2. **Experiment/Customize**: Use the Playground to test prompts, then customize with your data via API.[1][4]\\n3. **Build and Deploy**: Integrate into apps with code; agents handle complex tasks like querying databases.[2][3][5]\\n\\n### Real-World Examples\\n- **Customer Support Chatbot**: Use a language model like Claude, fine-tuned on your FAQs, to answer queries by pulling from S3-stored docs via RAG—faster and more accurate than generic bots.[1][2]\\n- **Content Generator**: Feed product details to Stability AI's image model to auto-create marketing visuals, integrated with Lambda for batch processing.[3][4]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "math_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', 'You are expert in maths'),\n",
        "    ('human', '{input}')\n",
        "])\n",
        "\n",
        "physics_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', 'You are expert in physics'),\n",
        "    ('human', '{input}')\n",
        "])\n",
        "\n",
        "general_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system','You are expert in general knowledge'),\n",
        "    ('human', '{input}')\n",
        "])"
      ],
      "metadata": {
        "id": "jGrZCgjF2CW8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_prompt(input):\n",
        "  query = input['input'].lower()\n",
        "\n",
        "  if 'maths' in query:\n",
        "    return math_prompt\n",
        "  elif 'physics' in query:\n",
        "    return physics_prompt\n",
        "  else:\n",
        "    return general_prompt"
      ],
      "metadata": {
        "id": "u2pqZLVy0LIs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "router = RunnableLambda(route_prompt)"
      ],
      "metadata": {
        "id": "CW_lchYG3nVl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain  = router | llm | StrOutputParser()\n",
        "chain.invoke({'input':'What is the square root of 4'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jQ_-ni1n4idc",
        "outputId": "e939e42f-486d-499e-dd27-6fb43d033248"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The square root of 4 is **2**.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": \"Explain Newton's first law\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "KAGDcUaw4w1v",
        "outputId": "1c5016ba-3319-49aa-bf0f-9d1ef2a5567a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Newton\\'s First Law of Motion, often called the **Law of Inertia**, is a foundational principle of classical physics that describes how objects behave in the absence of external forces.\\n\\nHere is a detailed explanation of the law, its components, and its implications.\\n\\n---\\n\\n## Newton\\'s First Law of Motion\\n\\nThe law can be stated formally as:\\n\\n> **An object at rest stays at rest, and an object in motion stays in motion with the same speed and in the same direction unless acted upon by an unbalanced external force.**\\n\\nIn simpler terms, objects are \"lazy\"—they resist changes to their current state of motion.\\n\\n---\\n\\n## Key Components of the Law\\n\\nThe law essentially consists of two parts, covering the two possible states of an object:\\n\\n### 1. The State of Rest\\n\\n* **\"An object at rest stays at rest...\"**\\n    * If an object is stationary (its velocity is zero), it will remain stationary forever unless something'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": \"What is Generative AI?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Biaeepqv45wD",
        "outputId": "a47d3608-e31f-4171-c221-ad7fa0d31def"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Generative AI is a **category of artificial intelligence models** that are designed to **create new, original content** rather than just analyzing or classifying existing data.\\n\\nHere is a comprehensive breakdown of what Generative AI is, how it works, and why it\\'s significant:\\n\\n---\\n\\n## 1. Core Definition\\n\\n**Generative AI** refers to deep-learning models that learn the patterns and structures of input data (such as text, images, audio, or code) and then use that knowledge to **generate novel, realistic outputs** that mimic the style, structure, and content of the training data.\\n\\nIn simple terms, if traditional AI is about **recognition** (e.g., \"Is this a cat or a dog?\"), Generative AI is about **creation** (e.g., \"Draw me a picture of a cat riding a dog.\").\\n\\n## 2. How It Works (The Training Process)\\n\\nGenerative AI models are typically trained on'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reformulation_prompt = ChatPromptTemplate.from_messages([\n",
        "   ('system', 'You are an expert question rewriter. Rewrite the following user question to be clearer, more specific, and technically precise. Original Question: {question} Rewritten Question:'),\n",
        "   ('human', '{question}')\n",
        "])\n"
      ],
      "metadata": {
        "id": "ZciE5ZsT4_ZE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_prompt = ChatPromptTemplate.from_messages([\n",
        "   ('system', \"\"\"Answer the following question in a structured format.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Format your response exactly as:\n",
        "\n",
        "Title:\n",
        "<short descriptive title>\n",
        "\n",
        "Explanation:\n",
        "<clear and detailed explanation>'),\n",
        "\"\"\"),\n",
        "   ('human', '{question}')\n",
        "])\n"
      ],
      "metadata": {
        "id": "ff4BgG6m-naI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = RunnableSequence(\n",
        "    reformulation_prompt,\n",
        "    llm,\n",
        "    StrOutputParser(),          # Output = reformulated question (string)\n",
        "    answer_prompt,\n",
        "    llm,\n",
        "    StrOutputParser()           # Final structured answer\n",
        ")\n"
      ],
      "metadata": {
        "id": "1Y3LRkMR_BT2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = workflow.invoke({\n",
        "    \"question\": \"What is LangChain?\"\n",
        "})\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Xxl1Xa_RNz",
        "outputId": "e1b6f548-2215-4f4b-c829-430f0445bf75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title:  \n",
            "LangChain Overview and Core Features\n",
            "\n",
            "Explanation:  \n",
            "**LangChain is an open-source framework for building applications powered by large language models (LLMs).** It simplifies integrating LLMs with external data sources, tools, and workflows through modular components like chains, agents, memory, and retrieval systems[1][3][5].  \n",
            "\n",
            "## Core Functionality  \n",
            "LangChain enables **chaining** components—such as prompts, LLMs, and tools—into multi-step sequences for complex tasks, with support for Python and JavaScript libraries[1][2][4]. Chains handle structured workflows, like rephrasing queries, fetching data, and generating responses, while agents add dynamic decision-making[1][2][5].  \n",
            "\n",
            "## Key Components  \n",
            "- **LLM Interface**: Standardized APIs for querying models like GPT, Bard, or PaLM via simple calls[3][5].  \n",
            "- **Retrieval Modules**: Tools for RAG systems, including vector databases (e.g., Chroma, Pinecone) for storing embeddings and semantic search[2][3][4].  \n",
            "- **Memory**: Systems for conversation history, from simple recall to entity-based context extraction[1][2][3].  \n",
            "- **Agents**: Autonomous systems that reason, call tools, and adapt dynamically[1][2][4].  \n",
            "- **Prompt Management**: Templates and engineering tools for consistent inputs[2][4].  \n",
            "\n",
            "## Primary Applications  \n",
            "Used for chatbots, question-answering, AI agents, document analysis, and data workflows by connecting LLMs to proprietary data without retraining[1][2][3]. Recent enhancements include LangGraph for durable agents with persistence and human-in-the-loop support[7].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AbIVKy7F_Z36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}